{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from toolbox import *\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "classes=list(df[\"class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=dict()\n",
    "for i in range(len(classes)):\n",
    "    temp_df=df[df[\"class\"]==classes[i]].reset_index()\n",
    "    fold=temp_df[\"fold\"].iloc[0]    # The fold of the first audio sample for the specific class\n",
    "    sample_name=temp_df[\"slice_file_name\"].iloc[0]\n",
    "    path=\"UrbanSound8K/audio/fold{0}/{1}\".format(fold, sample_name)\n",
    "    paths[classes[i]]=path\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(classes):\n",
    "    sample=paths[label]\n",
    "    plt.clf()\n",
    "    plt.title(label)\n",
    "    data, sample_rate=librosa.load(sample)\n",
    "    librosa.display.waveplot(data, sr=sample_rate)\n",
    "    # plt.savefig(\"outputs/{}.png\".format(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=paths[\"gun_shot\"]\n",
    "audio, sr=librosa.load(path)\n",
    "mfccs=librosa.feature.mfcc(audio, sr, n_mfcc=40)\n",
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(mfccs, x_axis='time', ax=ax)\n",
    "fig.colorbar(img, ax=ax)\n",
    "ax.set(title='MFCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(path):\n",
    "    audio, sr=librosa.load(path)\n",
    "    mfccs=librosa.feature.mfcc(audio, sr, n_mfcc=40)\n",
    "    return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "labels=[]\n",
    "folds=[]\n",
    "for i in range(len(df)):\n",
    "    fold=df[\"fold\"].iloc[i]\n",
    "    filename=df[\"slice_file_name\"].iloc[i]\n",
    "    path=\"UrbanSound8K/audio/fold{0}/{1}\".format(fold, filename)\n",
    "    mfccs=extract_mfcc(path)\n",
    "\n",
    "    # dataset.append((mfccs,df[\"classID\"].iloc[i]))\n",
    "    features.append(mfccs)\n",
    "    folds.append(fold)\n",
    "    labels.append(df[\"classID\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pt=torch.tensor(features)\n",
    "featur_pt\n",
    "labels_pt=torch.tensor(labels)\n",
    "labels_pt\n",
    "folds_pt=torch.tensor(folds)\n",
    "folds_pt\n",
    "# Saving the dataset to disk to prevent re-Loading\n",
    "torch.save(features_pt, \"UrbanSound8K/features_mfccs.pt\")\n",
    "torch.save(labels_pt, \"UrbanSound8K/labels.pt\")\n",
    "torch.save(folds_pt, \"UrbanSound8K/folds.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-frequency",
   "metadata": {},
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authorized-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=torch.load(\"UrbanSound8K/features_mfccs.pt\")\n",
    "labels=torch.load(\"UrbanSound8K/labels.pt\")\n",
    "folds=torch.load(\"UrbanSound8K/folds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ultimate-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(skip_fold):\n",
    "    local_features=[]\n",
    "    local_labels=[]\n",
    "    for i in range(len(folds)):\n",
    "        if folds[i]==skip_fold:\n",
    "            continue\n",
    "        local_features.append(features[i])\n",
    "        local_labels.append(labels[i])\n",
    "    local_features=torch.stack(local_features)\n",
    "    local_labels=torch.stack(local_labels)\n",
    "    return TensorDataset(local_features, local_labels), local_features, local_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, local_features, local_labels = get_dataset(skip_fold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dense-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(local_features.numpy(), local_labels.numpy(), test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6316, 1579)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size=int(0.2*len(dataset))\n",
    "train_size=len(dataset)-val_size\n",
    "\n",
    "train_ds, val_ds=random_split(dataset, [train_size, val_size])\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-payday",
   "metadata": {},
   "source": [
    "batch_size=128\n",
    "train_loader=DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader=DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Looking at a batch of data\n",
    "for x,y in train_loader:\n",
    "    print(f\"feautres: {x}\\nlabels: {y}\")\n",
    "    print(f\"dtypes: (x)->{x.dtype}, (y)->{y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broke-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"legend.loc\"] = \"best\"\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virtual-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "names = ['Air Conditioner',\n",
    "        'Car Horn',\n",
    "        'Children Playing',\n",
    "        'Dog bark',\n",
    "        'Drilling',\n",
    "        'Engine Idling',\n",
    "        'Gun Shot',\n",
    "        'Jackhammer',\n",
    "        'Siren',\n",
    "        'Street Music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chief-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [] \n",
    "\n",
    "#2 class\n",
    "for i in range(9):\n",
    "    for j in range(i + 1, 10):\n",
    "        experiments.append((i, j))\n",
    "\n",
    "#3 class\n",
    "experiments.extend([(0, 1, 2), (0, 1, 3), (0, 1, 4), (0, 1, 5)\\\n",
    "               , (0, 1, 6), (0, 1, 7), (0, 1, 8), (0, 1, 9)])\n",
    "#4 class\n",
    "#experiments.extend([(0, 1, 2, 3), (0, 1, 2, 4), (0, 1, 2, 5), (0, 1, 2, 6)\\\n",
    "#               , (0, 1, 2, 7), (0, 1, 2, 8), (0, 1, 2, 9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "double-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop\n"
     ]
    }
   ],
   "source": [
    "# filter python warnings\n",
    "def run():\n",
    "    torch.multiprocessing.freeze_support()\n",
    "    print('loop')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defensive-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dimensional-vintage",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b2fa8740b1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfraction_of_train_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfraction_of_train_samples_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_loaders_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraction_of_train_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/NDD_RF_DN/toolbox.py\u001b[0m in \u001b[0;36mcreate_loaders_set\u001b[0;34m(train_labels, test_labels, classes, trainset, testset, total_samples, batch)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m#print(\"setting \", i, \" to \", np.where(classes == trainset.targets[i])[0][0], trainset.targets[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubsetRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'tensors'"
     ]
    }
   ],
   "source": [
    "for classes in experiments:\n",
    "    fraction_of_train_samples_space = np.geomspace(.001, 1, num=8)\n",
    "    trials = 1\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    #resnet18\n",
    "    resnet_acc = list()\n",
    "    simplecnn = list() \n",
    "    cnn2layer = list()\n",
    "    complexcnn = list() \n",
    "    \n",
    "    for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    " \n",
    "        train_loader, test_loader = create_loaders_set(y_train, y_test, classes, train_ds, val_ds, int(fraction_of_train_samples * 10000))\n",
    "        \n",
    "        resnet18, input_size = initialize_model('resnet', num_classes, use_pretrained=True)\n",
    "        best_accuracy = np.mean([run_dn_image(resnet18, train_loader, test_loader) for _ in range(trials)])\n",
    "        resnet_acc.append(best_accuracy)\n",
    "        print(\"resnet Train Fraction:\", str(fraction_of_train_samples), \"Accuracy:\", str(best_accuracy))\n",
    "\n",
    "        \n",
    "        cnn32 = SimpleCNN32Filter(num_classes)\n",
    "        mean_accuracy = np.mean([run_dn_image(cnn32, train_loader, test_loader) for _ in range(trials)])\n",
    "        simplecnn.append(mean_accuracy)\n",
    "        print(\"simple Train Fraction:\", str(fraction_of_train_samples), \"Accuracy: \", str(mean_accuracy))\n",
    "\n",
    "        \n",
    "        cnn32 = SimpleCNN32Filter2Layers(num_classes)\n",
    "        mean_accuracy = np.mean([run_dn_image(cnn32, train_loader, test_loader) for _ in range(trials)])\n",
    "        cnn2layer.append(mean_accuracy)\n",
    "        print(\"Train Fraction:\", str(fraction_of_train_samples), \" Cnn 2 layer Accuracy: \", str(mean_accuracy))\n",
    "\n",
    "        \n",
    "        cnn32 = CNN5Layer(num_classes)\n",
    "        mean_accuracy = np.mean([run_dn_image(cnn32, train_loader, test_loader) for _ in range(trials)])\n",
    "        complexcnn.append(mean_accuracy)\n",
    "        print(\"complex Train Fraction:\", str(fraction_of_train_samples), \" Accuracy: \", str(mean_accuracy))\n",
    "    \n",
    "    #naive RF\n",
    "    rf_acc = list()\n",
    "    for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "        RF = RandomForestClassifier(n_estimators=100, n_jobs = -1)\n",
    "        best_accuracy = np.mean([run_rf_image_set(RF, X_train, y_train, X_test, y_test, int(fraction_of_train_samples * 10000), classes) for _ in range(trials)])\n",
    "        rf_acc.append(best_accuracy)\n",
    "        print(\"Train Fraction:\", str(fraction_of_train_samples))\n",
    "        print(\"Accuracy:\", str(best_accuracy))\n",
    "               \n",
    "    \n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 13, 10\n",
    "    plt.rcParams['font.size'] = 25\n",
    "    plt.rcParams['legend.fontsize'] = 16.5\n",
    "    plt.rcParams['legend.handlelength'] = 2.5\n",
    "    plt.rcParams['figure.titlesize'] = 20\n",
    "    plt.rcParams['xtick.labelsize'] = 15\n",
    "    plt.rcParams['ytick.labelsize'] = 15\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots() # create a new figure with a default 111 subplot\n",
    "    ax.plot(fraction_of_train_samples_space*10000, rf_acc, marker='X', markerfacecolor='red', markersize=8, color='green', linewidth=3, linestyle=\":\", label=\"RF\")\n",
    "    ax.plot(fraction_of_train_samples_space*10000, resnet_acc, marker='X', markerfacecolor='red', markersize=8, color='green', linewidth=3, linestyle=\"--\", label=\"Resnet18\")\n",
    "    ax.plot(fraction_of_train_samples_space*10000, simplecnn, marker='X', markerfacecolor='red', markersize=8, color='green', linewidth=3, label=\"simpleCNN\")\n",
    "    ax.plot(fraction_of_train_samples_space*10000, cnn2layer, marker='X', markerfacecolor='red', markersize=8, color='orange', linewidth=3, linestyle=\":\", label=\"2layerCNN\")\n",
    "    ax.plot(fraction_of_train_samples_space*10000, complexcnn, marker='X', markerfacecolor='red', markersize=8, color='orange', linewidth=3, label=\"5layerCNN\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Number of Train Samples', fontsize=18)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks([i*10000 for i in list(fraction_of_train_samples_space)])\n",
    "    ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    \n",
    "    ax.set_ylabel('Accuracy', fontsize=18)\n",
    "    \n",
    "    graph_title = str(classes[0]) + \" (\" + names[classes[0]] + \") \"\n",
    "    file_title = str(classes[0])\n",
    "    for j in range(1, len(classes)):\n",
    "        graph_title = graph_title + \" vs \" + str(classes[j]) + names[classes[j]]\n",
    "        file_title = file_title + \"-\" + str(classes[j])\n",
    "    ax.set_title(graph_title, fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cifar_results_fixed/\" + file_title)\n",
    "    table = pd.DataFrame(np.concatenate(([rf_acc], [resnet_acc], [simplecnn], [cnn2layer], [complexcnn]), axis=0))\n",
    "    algos = ['RF', 'resnet', 'simpleCNN', '2layercnn', '5layercnn']\n",
    "    table['algos'] = algos\n",
    "    cols = table.columns.tolist()\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    cols = pd.Index(cols)\n",
    "    table = table[cols]\n",
    "    table.to_csv(\"cifar_results_fixed/\" + file_title + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-government",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
